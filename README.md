# üöÄ xfmr-zem

[![Version](https://img.shields.io/badge/version-0.2.0-blue.svg)](https://github.com/OAI-Labs/xfmr-zem/releases)
[![License](https://img.shields.io/badge/license-Apache--2.0-green.svg)](LICENSE)
[![ZenML](https://img.shields.io/badge/Orchestration-ZenML-blueviolet)](https://zenml.io)
[![MCP](https://img.shields.io/badge/Interface-MCP-orange)](https://modelcontextprotocol.io)

**xfmr-zem** is a high-performance, unified data pipeline framework designed for the modern AI era. It seamlessly bridges **ZenML's** production-grade orchestration with specialized curation powerhouses like **NVIDIA NeMo Curator** and **Alibaba Data-Juicer** using the **Model Context Protocol (MCP)**.

---

## ‚ú® Key Features

- üèóÔ∏è **Config-Driven Power**: Define complex, production-ready pipelines in single YAML files.
- ‚ö° **True Parallel DAGs**: Execute independent processing branches concurrently using a custom `ParallelLocalOrchestrator`.
- üß† **Frontier LLM Integration**: Smart data masking, classification, and summarization via **Ollama** or **OpenAI**.
- üìä **Deep Observability**: Real-time profiling, per-tool performance metrics, and a beautiful integrated dashboard.
- üîÑ **Adaptive Caching**: Fine-grained, step-level cache control to optimize your development cycles.
- üîå **Cloud Native**: Native support for S3, GCS, and Parquet with seamless export to **Hugging Face Hub** and **Vector DBs**.

---

## üèóÔ∏è Architecture

```mermaid
graph TD
    YAML["üìÑ pipeline.yaml"] --> Client["üõ†Ô∏è Zem CLI / Client"]
    Client --> ZenML["üåÄ ZenML Orchestrator"]
    ZenML --> Parallel["‚ö° Parallel Local Orchestrator"]
    Parallel --> MCP_Bridge["üîó MCP Bridge"]
    
    subgraph "Specialized Servers (MCP)"
        MCP_Bridge --> Nemo["ü¶Å NeMo Curator (GPU)"]
        MCP_Bridge --> DJ["üßÉ Data-Juicer"]
        MCP_Bridge --> LLM["ü§ñ Frontier LLMs"]
        MCP_Bridge --> Prof["üìà Profiler"]
    end
    
    subgraph "Storage & Sinks"
        Nemo --> S3["‚òÅÔ∏è Cloud / Parquet"]
        DJ --> HF["ü§ó Hugging Face"]
        LLM --> VDB["üåê Vector DB"]
    end
```

---

## üöÄ Quick Start

### 1. Installation
```bash
git clone https://github.com/OAI-Labs/xfmr-zem.git
cd xfmr-zem
uv sync
```

### 2. Initialize a New Project
```bash
# Bootstrap a standalone project with a sample agent
uv run zem init my_project
cd my_project
```

### 3. Run Your First Pipeline
```bash
uv run zem run pipeline.yaml
```

### 4. Visualize & Inspect
```bash
# Open ZenML Dashboard
uv run zem dashboard

# Preview results with sampling
uv run zem preview <artifact_id> --sample --limit 5
```

---

## üìñ Guided Documentation

| Topic | Description | Link |
|-------|-------------|------|
| **Core Concepts** | Understand the Zem architecture and MCP model. | [AGENTS.md](AGENTS.md) |
| **Pipeline YAML** | How to write and validate your pipeline configs. | [Standard Example](tests/manual/standard_data_pipeline.yaml) |
| **Advanced Parallelism** | Setup true local concurrency. | [Parallel Guide](tests/manual/parallel_test.yaml) |
| **LLM & Sinks** | Connecting to external AI stacks. | [Phase 4 Demo](tests/manual/phase4_test.yaml) |

---

## ü§ù Contributing

We welcome contributions! Whether it's a new MCP server, a performance fix, or a typo in the docs, feel free to open a Pull Request. 

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ‚öñÔ∏è License

Distributed under the **Apache-2.0 License**. See `LICENSE` for more information.

---

<p align="center">
  Built with ‚ù§Ô∏è by the <b>OAI-Labs</b> Team
</p>
